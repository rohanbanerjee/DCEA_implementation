{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "implementation.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZgrcuBoDsD1"
      },
      "source": [
        "***Implementation of the paper - \"Do CNNs encode augmentations?\"***\n",
        "\n",
        "By: Sourav Sharan* and Rohan Banerjee* <br>\n",
        "*equal contributions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2k26sf41Em3A"
      },
      "source": [
        "Importing all needed libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clC-HN3uB2Xx"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import keras\n",
        "from numpy import save\n",
        "from tensorflow.keras.layers import Input, Conv2D, Dense, Flatten, Dropout\n",
        "from tensorflow.keras.layers import GlobalMaxPooling2D, MaxPooling2D\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.models import Model\n",
        "from google.colab.patches import cv2_imshow\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9ZnAmz5E2bk"
      },
      "source": [
        "Setting and spiltting up the Cifar10 dataset for training the CNN model and the RankNet model and testing both\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZybdVigvEtQa"
      },
      "source": [
        "input_shape = (32, 32, 3)\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
        "\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.20, random_state=1) # 0.25 x 0.8 = 0.2\n",
        "print(f\"x_train shape: {x_train.shape} - y_train shape: {y_train.shape}\")\n",
        "print(f\"x_val shape: {x_val.shape} - y_val shape: {y_val.shape}\")\n",
        "print(f\"x_test shape: {x_test.shape} - y_test shape: {y_test.shape}\")\n",
        "\n",
        "save('x_train.npy', x_train)\n",
        "save('y_train.npy', y_train)\n",
        "save('x_val.npy', x_val)\n",
        "save('y_val.npy', y_val)\n",
        "save('x_test.npy', x_test)\n",
        "save('y_test.npy', y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UAuvyuxrFQn_"
      },
      "source": [
        "Data Generator for augmenting the data. For our experiment, we chose only the \"zoom_in\" and \"zoom_out\" augmentations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6mMaIWTE_2g"
      },
      "source": [
        "datagen = ImageDataGenerator(\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True,\n",
        "    zoom_range=[0.5,1.0]\n",
        "    )\n",
        "datagen.fit(x_train)\n",
        "\n",
        "# Display the data to verify the augmentation\n",
        "\n",
        "fig, ax = plt.subplots(5, 5)\n",
        "k = 0\n",
        "aug_iter = datagen.flow(x_train[:25], batch_size=1,shuffle=False)\n",
        "\n",
        " \n",
        "for i in range(5):\n",
        "    for j in range(5):\n",
        "        \n",
        "        aug_img = next(aug_iter)[0].astype('uint8')\n",
        "        ax[i][j].imshow(aug_img, aspect='auto')\n",
        "        k += 1\n",
        "        \n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tf8FzwjTGPVY"
      },
      "source": [
        "Normalizing the data for training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSReM8crFkzo"
      },
      "source": [
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "y_train, y_test = y_train.flatten(), y_test.flatten()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2vD4V9_WUt5O"
      },
      "source": [
        "Building the model for training (with augmentations)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVCdq-vQGb6u"
      },
      "source": [
        "# number of classes\n",
        "K = len(set(y_train))\n",
        "\n",
        "# calculate total number of classes\n",
        "# for output layer\n",
        "print(\"number of classes:\", K)\n",
        "\n",
        "# Build the model using the functional API\n",
        "# input layer\n",
        "i = Input(shape=x_train[0].shape)\n",
        "#augmented = data_augmentation(i)\n",
        "#x = Conv2D(32, (3, 3), activation='relu', padding='same')(augmented)\n",
        "x = Conv2D(32, (3, 3), activation='relu', padding='same')(i)\n",
        "x = BatchNormalization()(x)\n",
        "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPooling2D((2, 2))(x)\n",
        "\n",
        "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPooling2D((2, 2))(x)\n",
        "\n",
        "x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPooling2D((2, 2))(x)\n",
        "\n",
        "x = Flatten()(x)\n",
        "x = Dropout(0.2)(x)\n",
        "\n",
        "# Hidden layer\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x = Dropout(0.2)(x)\n",
        "\n",
        "# last hidden layer i.e.. output layer\n",
        "x = Dense(K, activation='softmax')(x)\n",
        "\n",
        "model = Model(i, x)\n",
        "\n",
        "# model description\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKaPqix4U_HZ"
      },
      "source": [
        "Fitting the model and training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USVTSXLvU-Yg"
      },
      "source": [
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "r = model.fit(datagen.flow(x_train, y_train, batch_size=32), validation_data=(x_test, y_test), epochs=50, verbose =1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7EvsYdgbv5cb"
      },
      "source": [
        "model.save('/content/drive/MyDrive/Colab Notebooks/models/model_without_aug_test.h5')\n",
        "model = tf.keras.models.load_model('/content/drive/MyDrive/Colab Notebooks/models/model_without_aug_test.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHfcz-riynm7"
      },
      "source": [
        "Extracting the trained model except the last layer for the RankNet model and freezing it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXEa7e5ryfMs"
      },
      "source": [
        "feature_extractor = Model(inputs=model.input, outputs=model.layers[16].output)\n",
        "feature_extractor.trainable = False\n",
        "feature_extractor.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kz-_QxWL6420"
      },
      "source": [
        "Preparing training data for the RankNet model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RtxZJSl55F-r"
      },
      "source": [
        "import random\n",
        "x_rank_train = []\n",
        "y_rank_train = []\n",
        "for i in range(4):\n",
        "  for x in x_val:\n",
        "    a_fact = random.randint(5,9)/10 \n",
        "    b_fact = random.randint(5,9)/10\n",
        "    # the labels for the training data are the zoom factors\n",
        "    y_rank_train.append((a_fact-b_fact))\n",
        "    \n",
        "    datagen = ImageDataGenerator(zoom_range=[a_fact,a_fact])\n",
        "    \n",
        "    img = tf.expand_dims(x, axis=0)\n",
        "    aug_iter = datagen.flow(img, batch_size=1,shuffle=False)\n",
        "    aug_img_a = next(aug_iter)\n",
        "    datagen = ImageDataGenerator(zoom_range=[b_fact,b_fact])\n",
        "    \n",
        "    aug_iter = datagen.flow(img, batch_size=1,shuffle=False)\n",
        "    aug_img_b = next(aug_iter)\n",
        "    x_rank_train.append([aug_img_a,aug_img_b])\n",
        "    \n",
        "\n",
        "print(x_rank_train,y_rank_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1sk0gqj4us-"
      },
      "source": [
        "Defining the RankNet loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RN5EbQN4liC"
      },
      "source": [
        "def rank_loss(y_true, y_pred):\n",
        "  final = K.log(1+K.exp((-1*(tf.math.sign(y_true)*y_pred))))\n",
        "  return final"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sVIX5GIj4x6M"
      },
      "source": [
        "Creating and compiling the RankNet model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_Lc3nepyz1-"
      },
      "source": [
        "input_dim = x_train[0].shape\n",
        "input = Input(shape=(input_dim))\n",
        "\n",
        "x = feature_extractor(input)\n",
        "\n",
        "# adding new layers to the trained model\n",
        "x = Dropout(0.2)(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x = Dropout(0.2)(x)\n",
        "x = Dense(1, activation='linear')(x)\n",
        "base_model = Model(input, x)\n",
        "\n",
        "# prinitng model summary for verification\n",
        "for i,layer in enumerate(base_model.layers):\n",
        "    print(i,layer.name,layer.trainable)\n",
        "print(base_model.summary())\n",
        "\n",
        "\n",
        "# creating the ranknet model\n",
        "input_a = Input(shape=(input_dim))\n",
        "input_b = Input(shape=(input_dim))\n",
        "\n",
        "a_score = base_model(input_a)\n",
        "b_score = base_model(input_b)\n",
        "\n",
        "# subtract scores {scores are amount of augmentation in our case}\n",
        "diff = tf.keras.layers.Subtract()([a_score, b_score])\n",
        "prob = diff\n",
        "\n",
        "# Build model\n",
        "meta_model = Model(inputs = [input_a, input_b], outputs = prob)\n",
        "meta_model.compile(optimizer='adam', loss=rank_loss, metrics=['accuracy'])\n",
        "meta_model.summary() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4I9sILt8vyu"
      },
      "source": [
        "Normalizing data for training the RankNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8eW-JuU483P"
      },
      "source": [
        "x_rank_train, x_rank_test = x_rank_train / 255.0, x_rank_test / 255.0\n",
        "\n",
        "print(x_rank_train[0][1].shape)\n",
        "x_rank_train_a = []\n",
        "x_rank_train_b = []\n",
        "x_rank_test_a = []\n",
        "x_rank_test_b = []\n",
        "\n",
        "for x in x_rank_train:\n",
        "  x_rank_train_a.append(x[0][0]/255.0)\n",
        "  x_rank_train_b.append(x[1][0]/255.0)\n",
        "for x in x_rank_test:\n",
        "  x_rank_test_a.append(x[0][0]/255.0)\n",
        "  x_rank_test_b.append(x[1][0]/255.0)\n",
        "\n",
        "x_rank_train_a = np.array(x_rank_train_a)\n",
        "x_rank_train_b = np.array(x_rank_train_b)\n",
        "x_rank_test_a = np.array(x_rank_test_a)\n",
        "x_rank_test_b = np.array(x_rank_test_b)\n",
        "y_rank_train = np.array(y_rank_train)\n",
        "y_rank_test = np.array(y_rank_test)\n",
        "\n",
        "print(len(x_rank_train_a),len(x_rank_train_b),len(x_rank_test_a),len(x_rank_test_b))\n",
        "print(x_rank_train_a.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjkbtald9dQH"
      },
      "source": [
        "Training the RankNet model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ns74-jl59CzP"
      },
      "source": [
        "r = meta_model.fit([x_rank_train_a,x_rank_train_b], y_rank_train, epochs=50, verbose =1,batch_size=32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGIGatIe-ADt"
      },
      "source": [
        "Predicting how many images have been predicted with the correct zoom factor hence proving that CNNs enocode augmentations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NpTppKg39g1k"
      },
      "source": [
        "gt_a = 0\n",
        "gt_b = 0\n",
        "pred_a = 0\n",
        "pred_b = 0 \n",
        "\n",
        "for gt, pred in zip(y_rank_test, results):\n",
        "  #print(gt,pred)\n",
        "  if gt > 0:\n",
        "    gt_b += 1\n",
        "    if pred > 0:\n",
        "      pred_b += 1\n",
        "  else:\n",
        "    gt_a += 1\n",
        "    if pred < 0:\n",
        "      pred_a += 1\n",
        "\n",
        "\n",
        "print('where a has more aug : ', pred_a, ' / ', gt_a)\n",
        "print('where b has more aug : ', pred_b, ' / ', gt_b)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}